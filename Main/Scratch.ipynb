{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Safe Absorbing States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dependencies.NN import *\n",
    "from dependencies.LTL import *\n",
    "from dependencies.Utility_funcs import *\n",
    "from dependencies.maps import grid_world\n",
    "from dependencies.RL_LTL import RL_LTL\n",
    "\n",
    "from dependencies.csrl.mdp import GridMDP\n",
    "from dependencies.csrl.oa import OmegaAutomaton\n",
    "from dependencies.csrl import ControlSynthesis\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights(f'outputs/models/sequential_delivery_{n}_p{gw.p}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Omega-automaton states (including the trap state): 6\n"
     ]
    }
   ],
   "source": [
    "gw = grid_world(name='sequential_delivery', n_danger=5, plot=False, p=1)\n",
    "csrl = gw.csrl\n",
    "model = build_model(gw.ch_states[(0,0,0,0)].shape, gw.csrl.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################\n",
      "C: 0.5 | tow: 0.2\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'grid_world' object has no attribute 'ch_states'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m gw \u001b[38;5;241m=\u001b[39m grid_world(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msequential_delivery\u001b[39m\u001b[38;5;124m'\u001b[39m, n_danger\u001b[38;5;241m=\u001b[39mn, plot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, csrl\u001b[38;5;241m=\u001b[39mcsrl)\n\u001b[1;32m      3\u001b[0m env \u001b[38;5;241m=\u001b[39m RL_LTL(gw, model)\n\u001b[0;32m----> 5\u001b[0m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmart_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m env\u001b[38;5;241m.\u001b[39mget_policy(\u001b[38;5;241m1\u001b[39m, reset_tables\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutputs/Ours/gen_mdp/sequential_delivery_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_p\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgw\u001b[38;5;241m.\u001b[39mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/Research/Uwaterloo/RL-LTL/Main/dependencies/RL_LTL.py:59\u001b[0m, in \u001b[0;36mRL_LTL.train\u001b[0;34m(self, num_training_epochs, start, T, smart_start, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_training_epochs):\n\u001b[1;32m     57\u001b[0m     t1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     58\u001b[0m     state_history, channeled_states, trajectory, action_history, reward_history, better_policy, best_val_len \u001b[38;5;241m=\u001b[39m MC_learning(\n\u001b[0;32m---> 59\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgw\u001b[38;5;241m.\u001b[39mcsrl, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgw\u001b[38;5;241m.\u001b[39mLTL_formula, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgw\u001b[38;5;241m.\u001b[39mpredicates\u001b[38;5;241m.\u001b[39mcopy(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgw\u001b[38;5;241m.\u001b[39mcsrl\u001b[38;5;241m.\u001b[39mreward, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mch_states\u001b[49m,\n\u001b[1;32m     60\u001b[0m         N \u001b[38;5;241m=\u001b[39m N, W \u001b[38;5;241m=\u001b[39m W, Q \u001b[38;5;241m=\u001b[39m Q, P \u001b[38;5;241m=\u001b[39m P, C\u001b[38;5;241m=\u001b[39mC, tow\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtow, n_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMCTS_samples, visited\u001b[38;5;241m=\u001b[39mvisited_train,\n\u001b[1;32m     61\u001b[0m         start\u001b[38;5;241m=\u001b[39mstart, search_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_depth, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, T\u001b[38;5;241m=\u001b[39mi, K\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mK, NN_value_active\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNN_value_active,\n\u001b[1;32m     62\u001b[0m         run_num\u001b[38;5;241m=\u001b[39mepoch, ltl_f_rew\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, reachability\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, best_val_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_val_len, danger_zone\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdanger_zone)\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvisited_states_train \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m state_history\n\u001b[1;32m     65\u001b[0m     t2 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'grid_world' object has no attribute 'ch_states'"
     ]
    }
   ],
   "source": [
    "for n in range(5, 2, -1):\n",
    "    gw = grid_world(name='sequential_delivery', n_danger=n, plot=False, p=1, csrl=csrl)\n",
    "    env = RL_LTL(gw, model)\n",
    "\n",
    "    env.train(20, smart_start=True)\n",
    "    env.get_policy(1, reset_tables=False)\n",
    "\n",
    "    with open(f'outputs/Ours/gen_mdp/sequential_delivery_{n}_p{gw.p}.txt', 'w') as f:\n",
    "        f.write('succ_rate:\\n')\n",
    "        f.write(', '.join(str(i) for i in env.policy_succ_rate))\n",
    "\n",
    "    model.save_weights(f'outputs/models/gen_mdp/sequential_delivery_p{gw.p}')\n",
    "    np.save(f'outputs/Ours/sequential_delivery_{n}_p{gw.p}', env.policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mine_craft_1\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "mine_craft_2\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "mine_craft_3\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "mine_craft_4\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "mine_craft_5\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "mine_craft_6\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "mine_craft_7\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "mine_craft_8\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "mine_craft_9\n",
      "Number of Omega-automaton states (including the trap state): 7\n",
      "mine_craft_10\n",
      "Number of Omega-automaton states (including the trap state): 7\n"
     ]
    }
   ],
   "source": [
    "for name in ['mine_craft_'+str(j) for j in range(1,11)]:\n",
    "    print(name)\n",
    "    gw = grid_world(name=name, plot=False, p=0.8)\n",
    "    Q =gw.csrl.q_learning(T=100,K=3000000)\n",
    "    np.save(f'outputs/CSRL/{name}_p{gw.p}', Q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Omega-automaton states (including the trap state): 7\n",
      "Running 500 simulations with 28 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 483 / 500 = 0.966\n"
     ]
    }
   ],
   "source": [
    "name = 'mine_craft_10'\n",
    "gw = grid_world(name=name, plot=False, p=1)\n",
    "Q = np.load(f'outputs/CSRL/{name}_p{1}.npy')\n",
    "policy2=np.argmax(Q,axis=4)\n",
    "value2=np.max(Q,axis=4)\n",
    "episodes, rew, rew_table = run_Q_test(gw.csrl, policy2, gw.LTL_formula, gw.predicates, start=None, T=28, runs=500, verbose=0, reachability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mine_craft_1\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 10 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 535 / 1000 = 0.535\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 15 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 911 / 1000 = 0.911\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 20 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 994 / 1000 = 0.994\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 25 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 999 / 1000 = 0.999\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 30 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 1000 / 1000 = 1.0\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 35 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 1000 / 1000 = 1.0\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 40 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 1000 / 1000 = 1.0\n",
      "mine_craft_2\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 10 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 538 / 1000 = 0.538\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 15 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 926 / 1000 = 0.926\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 20 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 993 / 1000 = 0.993\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 25 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 999 / 1000 = 0.999\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 30 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 1000 / 1000 = 1.0\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 35 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 1000 / 1000 = 1.0\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 40 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 1000 / 1000 = 1.0\n",
      "mine_craft_3\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 10 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 142 / 1000 = 0.142\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 15 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 721 / 1000 = 0.721\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 20 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 955 / 1000 = 0.955\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 25 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 990 / 1000 = 0.99\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 30 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 1000 / 1000 = 1.0\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 35 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 1000 / 1000 = 1.0\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 40 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 1000 / 1000 = 1.0\n",
      "mine_craft_4\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 10 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 549 / 1000 = 0.549\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 15 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 907 / 1000 = 0.907\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 20 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 996 / 1000 = 0.996\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 25 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 999 / 1000 = 0.999\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 30 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 1000 / 1000 = 1.0\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 35 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 1000 / 1000 = 1.0\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 40 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 1000 / 1000 = 1.0\n",
      "mine_craft_5\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 10 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 0 / 1000 = 0.0\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 15 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 171 / 1000 = 0.171\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 20 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 634 / 1000 = 0.634\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 25 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 913 / 1000 = 0.913\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 30 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 989 / 1000 = 0.989\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 35 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 998 / 1000 = 0.998\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 40 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 999 / 1000 = 0.999\n",
      "mine_craft_6\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 10 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 0 / 1000 = 0.0\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 15 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 58 / 1000 = 0.058\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 20 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 459 / 1000 = 0.459\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 25 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 822 / 1000 = 0.822\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 30 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 967 / 1000 = 0.967\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 35 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 994 / 1000 = 0.994\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 40 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 1000 / 1000 = 1.0\n",
      "mine_craft_7\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 10 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 0 / 1000 = 0.0\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 15 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 0 / 1000 = 0.0\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 20 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 143 / 1000 = 0.143\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 25 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 572 / 1000 = 0.572\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 30 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 891 / 1000 = 0.891\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 35 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 975 / 1000 = 0.975\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 40 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 999 / 1000 = 0.999\n",
      "mine_craft_8\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 10 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 8 / 1000 = 0.008\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 15 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 205 / 1000 = 0.205\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 20 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 612 / 1000 = 0.612\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 25 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 900 / 1000 = 0.9\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 30 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 978 / 1000 = 0.978\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 35 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 994 / 1000 = 0.994\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 40 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 999 / 1000 = 0.999\n",
      "mine_craft_9\n",
      "Number of Omega-automaton states (including the trap state): 7\n",
      "Running 1000 simulations with 10 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 0 / 1000 = 0.0\n",
      "Number of Omega-automaton states (including the trap state): 7\n",
      "Running 1000 simulations with 15 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 0 / 1000 = 0.0\n",
      "Number of Omega-automaton states (including the trap state): 7\n",
      "Running 1000 simulations with 20 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 0 / 1000 = 0.0\n",
      "Number of Omega-automaton states (including the trap state): 7\n",
      "Running 1000 simulations with 25 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 0 / 1000 = 0.0\n",
      "Number of Omega-automaton states (including the trap state): 7\n",
      "Running 1000 simulations with 30 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 0 / 1000 = 0.0\n",
      "Number of Omega-automaton states (including the trap state): 7\n",
      "Running 1000 simulations with 35 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 0 / 1000 = 0.0\n",
      "Number of Omega-automaton states (including the trap state): 7\n",
      "Running 1000 simulations with 40 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 0 / 1000 = 0.0\n",
      "mine_craft_10\n",
      "Number of Omega-automaton states (including the trap state): 7\n",
      "Running 1000 simulations with 10 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 0 / 1000 = 0.0\n",
      "Number of Omega-automaton states (including the trap state): 7\n",
      "Running 1000 simulations with 15 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 0 / 1000 = 0.0\n",
      "Number of Omega-automaton states (including the trap state): 7\n",
      "Running 1000 simulations with 20 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 4 / 1000 = 0.004\n",
      "Number of Omega-automaton states (including the trap state): 7\n",
      "Running 1000 simulations with 25 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 158 / 1000 = 0.158\n",
      "Number of Omega-automaton states (including the trap state): 7\n",
      "Running 1000 simulations with 30 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 548 / 1000 = 0.548\n",
      "Number of Omega-automaton states (including the trap state): 7\n",
      "Running 1000 simulations with 35 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 849 / 1000 = 0.849\n",
      "Number of Omega-automaton states (including the trap state): 7\n",
      "Running 1000 simulations with 40 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 969 / 1000 = 0.969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([17.72, 38.99, 57.9 , 73.52, 83.73, 88.1 , 89.66])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_rates = []\n",
    "for name in ['mine_craft_'+str(j) for j in range(1,11)]:\n",
    "    print(name)\n",
    "    tmp = []\n",
    "    for t in range(10,41, 5):\n",
    "        gw = grid_world(name=name, plot=False, p=0.8)\n",
    "        Q = np.load(f'outputs/CSRL/{name}_p{gw.p}.npy')\n",
    "        policy2=np.argmax(Q,axis=4)\n",
    "        value2=np.max(Q,axis=4)\n",
    "        episodes, rew, rew_table = run_Q_test(gw.csrl, policy2, gw.LTL_formula, gw.predicates, start=None, T=t, runs=1000, verbose=0, reachability=True)\n",
    "        tmp.append(100*np.sum(rew)/len(rew))\n",
    "    all_rates.append(tmp)\n",
    "np.array(all_rates).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[53.5, 91.1, 99.4, 99.9, 100.0, 100.0, 100.0]\n",
      "[53.8, 92.6, 99.3, 99.9, 100.0, 100.0, 100.0]\n",
      "[14.2, 72.1, 95.5, 99.0, 100.0, 100.0, 100.0]\n",
      "[54.9, 90.7, 99.6, 99.9, 100.0, 100.0, 100.0]\n",
      "[0.0, 17.1, 63.4, 91.3, 98.9, 99.8, 99.9]\n",
      "[0.0, 5.8, 45.9, 82.2, 96.7, 99.4, 100.0]\n",
      "[0.0, 0.0, 14.3, 57.2, 89.1, 97.5, 99.9]\n",
      "[0.8, 20.5, 61.2, 90.0, 97.8, 99.4, 99.9]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.4, 15.8, 54.8, 84.9, 96.9]\n"
     ]
    }
   ],
   "source": [
    "for i in all_rates:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18.1, 38.2, 57.1, 74.3, 83.4, 88.1, 89.5, 89.8, 90. ])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(all_rates).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[33.0, 67.1, 88.5, 93.6, 97.9, 98.4, 99.0],\n",
       " [14.7, 48.7, 82.2, 94.5, 98.8, 98.9, 99.4],\n",
       " [10.6, 46.1, 79.6, 94.0, 97.9, 99.2, 98.4],\n",
       " [29.1, 67.6, 90.8, 97.6, 98.6, 99.3, 99.6],\n",
       " [0.0, 6.9, 36.7, 77.0, 92.1, 97.6, 99.2],\n",
       " [0.0, 0.7, 13.2, 43.6, 68.0, 86.6, 95.8],\n",
       " [0.0, 0.0, 5.2, 22.9, 53.2, 74.3, 89.7],\n",
       " [0.0, 0.2, 0.8, 3.6, 17.1, 48.4, 73.9],\n",
       " [0.0, 0.0, 0.0, 2.3, 14.7, 44.0, 70.9],\n",
       " [0.0, 0.0, 0.0, 3.1, 14.3, 41.0, 63.8]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mine_craft_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 10 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 330 / 1000 = 0.33\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 15 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 671 / 1000 = 0.671\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 20 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 885 / 1000 = 0.885\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 25 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 936 / 1000 = 0.936\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 30 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 979 / 1000 = 0.979\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 35 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 984 / 1000 = 0.984\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 40 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 990 / 1000 = 0.99\n",
      "mine_craft_2\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 10 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 147 / 1000 = 0.147\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 15 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 487 / 1000 = 0.487\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 20 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 822 / 1000 = 0.822\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 25 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 945 / 1000 = 0.945\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 30 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 988 / 1000 = 0.988\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 35 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 989 / 1000 = 0.989\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 40 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 994 / 1000 = 0.994\n",
      "mine_craft_3\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 10 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 106 / 1000 = 0.106\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 15 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 461 / 1000 = 0.461\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 20 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 796 / 1000 = 0.796\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 25 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 940 / 1000 = 0.94\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 30 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 979 / 1000 = 0.979\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 35 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 992 / 1000 = 0.992\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 40 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 984 / 1000 = 0.984\n",
      "mine_craft_4\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 10 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 291 / 1000 = 0.291\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 15 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 676 / 1000 = 0.676\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 20 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 908 / 1000 = 0.908\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 25 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 976 / 1000 = 0.976\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 30 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 986 / 1000 = 0.986\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 35 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 993 / 1000 = 0.993\n",
      "Number of Omega-automaton states (including the trap state): 4\n",
      "Running 1000 simulations with 40 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 996 / 1000 = 0.996\n",
      "mine_craft_5\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 10 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 0 / 1000 = 0.0\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 15 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 69 / 1000 = 0.069\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 20 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 367 / 1000 = 0.367\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 25 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 770 / 1000 = 0.77\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 30 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 921 / 1000 = 0.921\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 35 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 976 / 1000 = 0.976\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 40 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 992 / 1000 = 0.992\n",
      "mine_craft_6\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 10 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 0 / 1000 = 0.0\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 15 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 7 / 1000 = 0.007\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 20 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 132 / 1000 = 0.132\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 25 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 436 / 1000 = 0.436\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 30 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 680 / 1000 = 0.68\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 35 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 866 / 1000 = 0.866\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 40 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 958 / 1000 = 0.958\n",
      "mine_craft_7\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 10 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 0 / 1000 = 0.0\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 15 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 0 / 1000 = 0.0\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 20 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 52 / 1000 = 0.052\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 25 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 229 / 1000 = 0.229\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 30 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 532 / 1000 = 0.532\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 35 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 743 / 1000 = 0.743\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 40 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 897 / 1000 = 0.897\n",
      "mine_craft_8\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 10 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 0 / 1000 = 0.0\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 15 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 2 / 1000 = 0.002\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 20 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 8 / 1000 = 0.008\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 25 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 36 / 1000 = 0.036\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 30 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 171 / 1000 = 0.171\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 35 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 484 / 1000 = 0.484\n",
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 1000 simulations with 40 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 739 / 1000 = 0.739\n",
      "mine_craft_9\n",
      "Number of Omega-automaton states (including the trap state): 7\n",
      "Running 1000 simulations with 10 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 0 / 1000 = 0.0\n",
      "Number of Omega-automaton states (including the trap state): 7\n",
      "Running 1000 simulations with 15 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 0 / 1000 = 0.0\n",
      "Number of Omega-automaton states (including the trap state): 7\n",
      "Running 1000 simulations with 20 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 0 / 1000 = 0.0\n",
      "Number of Omega-automaton states (including the trap state): 7\n",
      "Running 1000 simulations with 25 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 23 / 1000 = 0.023\n",
      "Number of Omega-automaton states (including the trap state): 7\n",
      "Running 1000 simulations with 30 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 147 / 1000 = 0.147\n",
      "Number of Omega-automaton states (including the trap state): 7\n",
      "Running 1000 simulations with 35 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 440 / 1000 = 0.44\n",
      "Number of Omega-automaton states (including the trap state): 7\n",
      "Running 1000 simulations with 40 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 709 / 1000 = 0.709\n",
      "mine_craft_10\n",
      "Number of Omega-automaton states (including the trap state): 7\n",
      "Running 1000 simulations with 10 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 0 / 1000 = 0.0\n",
      "Number of Omega-automaton states (including the trap state): 7\n",
      "Running 1000 simulations with 15 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 0 / 1000 = 0.0\n",
      "Number of Omega-automaton states (including the trap state): 7\n",
      "Running 1000 simulations with 20 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 0 / 1000 = 0.0\n",
      "Number of Omega-automaton states (including the trap state): 7\n",
      "Running 1000 simulations with 25 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 31 / 1000 = 0.031\n",
      "Number of Omega-automaton states (including the trap state): 7\n",
      "Running 1000 simulations with 30 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 143 / 1000 = 0.143\n",
      "Number of Omega-automaton states (including the trap state): 7\n",
      "Running 1000 simulations with 35 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 410 / 1000 = 0.41\n",
      "Number of Omega-automaton states (including the trap state): 7\n",
      "Running 1000 simulations with 40 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 638 / 1000 = 0.638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 8.74, 23.73, 39.7 , 53.22, 65.26, 78.77, 88.97])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_rates = []\n",
    "for name in ['mine_craft_'+str(j) for j in range(1,11)]:\n",
    "    print(name)\n",
    "    tmp = []\n",
    "    for t in range(10,41, 5):\n",
    "        gw = grid_world(name=name, plot=False, p=0.8)\n",
    "        policy = np.load(f'outputs/Ours/{name}_p{gw.p}.npy')\n",
    "        episodes, rew, rew_table = run_Q_test(gw.csrl, policy, gw.LTL_formula, gw.predicates, start=None, T=t, runs=1000, verbose=0, reachability=True)\n",
    "        tmp.append(100*np.sum(rew)/len(rew))\n",
    "    all_rates.append(tmp)\n",
    "np.array(all_rates).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Omega-automaton states (including the trap state): 6\n",
      "Running 100 simulations with 100 time-steps...\n",
      "Test finished with:\n",
      "\tsuccess rate: 99 / 100 = 0.99\n"
     ]
    }
   ],
   "source": [
    "# running the sequential delivery case for 3 danger zones with 3 million iterations and p=0.8\n",
    "gw = grid_world(name='sequential_delivery', n_danger=3, plot=False, p=0.8)\n",
    "Q =gw.csrl.q_learning(T=100,K=3000000)\n",
    "np.save(f'outputs/CSRL/sequential_delivery_3_p{gw.p}', Q)\n",
    "\n",
    "policy2=np.argmax(Q,axis=4)\n",
    "value2=np.max(Q,axis=4)\n",
    "episodes, rew, rew_table = run_Q_test(gw.csrl, policy2, gw.LTL_formula, gw.predicates, start=None, T=100, runs=100, verbose=0, reachability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 1000 simulations with 50 time-steps...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test finished with:\n",
      "\tsuccess rate: 982 / 1000 = 0.982\n"
     ]
    }
   ],
   "source": [
    "episodes, rew, rew_table = run_Q_test(gw.csrl, policy2, gw.LTL_formula, gw.predicates, start=None, T=50, runs=1000, verbose=0, reachability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gw.mdp.plot(value=rew_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.load(f'outputs/CSRL/mine_craft_9_p{gw.p}.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Omega-automaton states (including the trap state): 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<dependencies.csrl.oa.OmegaAutomaton at 0x7f0fe82f8160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# LTL Specification\n",
    "ltl = '(F G a | F G b) & G !d'\n",
    "\n",
    "# Translate the LTL formula to an LDBA\n",
    "oa = OmegaAutomaton(ltl)\n",
    "print('Number of Omega-automaton states (including the trap state):',oa.shape[1])\n",
    "display(oa)\n",
    "\n",
    "# MDP Description\n",
    "shape = (3,3)\n",
    "# E: Empty, T: Trap, B: Obstacle\n",
    "structure = np.array([\n",
    "['E',  'E',  'E'],\n",
    "['E',  'E',  'E'],\n",
    "['E',  'E',  'E'],\n",
    "])\n",
    "\n",
    "# Labels of the states\n",
    "label = np.array([\n",
    "[('a',),(),('b',)],\n",
    "[(),('d',),    ()],\n",
    "[(),    (),    ()],\n",
    "],dtype=object)\n",
    "# Colors of the labels\n",
    "lcmap={\n",
    "    ('a',):'lightgreen',\n",
    "    ('b',):'lightgreen',\n",
    "    ('d',):'pink'\n",
    "}\n",
    "p = 1\n",
    "grid_mdp = GridMDP(shape=shape,structure=structure,label=label,lcmap=lcmap, p=p, figsize=5)  # Use figsize=4 for smaller figures\n",
    "grid_mdp.plot()\n",
    "\n",
    "# Construct the product MDP\n",
    "csrl = ControlSynthesis(grid_mdp,oa)\n",
    "max_rew = round(csrl.reward.max(), 3)\n",
    "\n",
    "s_vectors = state_vectors(csrl)\n",
    "enc = list(np.unique(grid_mdp.label))\n",
    "enc.pop(enc.index(()))\n",
    "ch_states = channeled(csrl, enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': [0], 'b': [2], 'd': [4]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_t = \"(<> [] a \\/ <> [] b) /\\ [] ~d\"\n",
    "\n",
    "LTL_formula = parser.parse(full_t)\n",
    "predicates=get_predicates(grid_mdp)\n",
    "predicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(ch_states[(0,0,0,0)].shape, csrl.shape[-1])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ) MCTS conf: -0.36 , det: 1.0 | LTL [---]  LDBA [ 0.0 ] path: [5, 5, 8, 7, 6, 3, 0, 0, 0, 3, 4]\n",
      "1 ) MCTS conf: -0.39 , det: 1.0 | LTL [+++]  LDBA [ 0.01 ] path: [8, 7, 6, 3, 0, 0]\n",
      "2 ) MCTS conf: 1.0 , det: 1.0 | LTL [+++]  LDBA [ 0.01 ] path: [6, 3, 0, 0]\n",
      "3 ) MCTS conf: 0.58 , det: 1.0 | LTL [+++]  LDBA [ 0.01 ] path: [8, 7, 6, 3, 0, 0]\n",
      "4 ) MCTS conf: 0.96 , det: 1.0 | LTL [+++]  LDBA [ 0.01 ] path: [1, 0, 0]\n",
      "5 ) MCTS conf: 0.97 , det: 1.0 | LTL [+++]  LDBA [ 0.01 ] path: [8, 7, 6, 3, 0, 0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/srmt/Research/Uwaterloo/RL-LTL/Main/Scratch.ipynb Cell 7\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/srmt/Research/Uwaterloo/RL-LTL/Main/Scratch.ipynb#W6sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m             y2_train_curr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(reward_history) \u001b[39m+\u001b[39m LTL_coef\u001b[39m*\u001b[39mreward_history[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/srmt/Research/Uwaterloo/RL-LTL/Main/Scratch.ipynb#W6sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m             y2_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((y2_train, y2_train_curr[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]),\u001b[39m0\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/srmt/Research/Uwaterloo/RL-LTL/Main/Scratch.ipynb#W6sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m         tr_hist \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(x_train, [y1_train, y2_train], epochs\u001b[39m=\u001b[39;49mepochs, batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/srmt/Research/Uwaterloo/RL-LTL/Main/Scratch.ipynb#W6sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m                             steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch \u001b[39mif\u001b[39;49;00m \u001b[39mlen\u001b[39;49m(x_train)\u001b[39m>\u001b[39;49msteps_per_epoch\u001b[39m*\u001b[39;49mepochs\u001b[39m*\u001b[39;49mbatch_size \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/srmt/Research/Uwaterloo/RL-LTL/Main/Scratch.ipynb#W6sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m         train_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_hist\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/srmt/Research/Uwaterloo/RL-LTL/Main/Scratch.ipynb#W6sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTrain wins:\u001b[39m\u001b[39m\"\u001b[39m,train_wins,\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m, num_training_epochs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1651\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1746\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    379\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    380\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    381\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    382\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    383\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    384\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LTL_coef = 10\n",
    "NN_value_active = False\n",
    "search_depth = 100\n",
    "MCTS_samples = 100\n",
    "training = True\n",
    "epochs = 15\n",
    "C = 1\n",
    "tow = 0.1\n",
    "T = [25]\n",
    "K = 1\n",
    "batch_size = 32\n",
    "steps_per_epoch = 4\n",
    "idx = 0\n",
    "success_rates = []\n",
    "succes_std = []\n",
    "win_hist = []\n",
    "train_history = []\n",
    "best_val_len = {}\n",
    "for s in csrl.states(): best_val_len[s] = (0.001, 99999)\n",
    "\n",
    "num_training_epochs =  10\n",
    "# os.remove(\"outputs/Log_run.txt\")\n",
    "for i in T:\n",
    "    idx += 1\n",
    "    train_wins = 0\n",
    "    # model = build_model(ch_states[(0,0,0,0)].shape, csrl.shape[-1])\n",
    "    N, W, Q, P, visited_train = np.zeros(csrl.shape), np.zeros(csrl.shape), np.zeros(csrl.shape), np.zeros(csrl.shape), set()\n",
    "    for epoch in range(num_training_epochs):\n",
    "        t1 = time.time()\n",
    "        state_history, channeled_states, trajectory, action_history, reward_history, better_policy, best_val_len = MC_learning(csrl, model, LTL_formula,\n",
    "                predicates, csrl.reward, ch_states, N = N, W = W, Q = Q, P = P, C=C, tow=tow, n_samples=MCTS_samples, visited=visited_train,\n",
    "                start=None, search_depth=search_depth, verbose=0, T=i, K=K, NN_value_active=NN_value_active, run_num=epoch, ltl_f_rew=False, reachability=True, \n",
    "                best_val_len = best_val_len)\n",
    "        \n",
    "        if reward_history[-1]>0:\n",
    "            train_wins+=1\n",
    "            NN_value_active = True\n",
    "\n",
    "        if training and len(action_history)>0:\n",
    "            if epoch==0:\n",
    "                x_train = np.array(channeled_states)[:-1]\n",
    "                y1_train = np.array(better_policy)\n",
    "                y2_train = np.array(reward_history) + LTL_coef*reward_history[-1]\n",
    "                y2_train = y2_train[:-1]\n",
    "            else:\n",
    "                x_train = np.concatenate((x_train, np.array(channeled_states)[:-1]),0)\n",
    "                y1_train = np.concatenate((y1_train, np.array(better_policy)),0)\n",
    "                y2_train_curr = np.array(reward_history) + LTL_coef*reward_history[-1]\n",
    "                y2_train = np.concatenate((y2_train, y2_train_curr[:-1]),0)\n",
    "            tr_hist = model.fit(x_train, [y1_train, y2_train], epochs=epochs, batch_size=batch_size,\n",
    "                                steps_per_epoch=steps_per_epoch if len(x_train)>steps_per_epoch*epochs*batch_size else None, verbose=0)\n",
    "            train_history += tr_hist.history['loss']\n",
    "    print(\"Train wins:\",train_wins,\"/\", num_training_epochs)\n",
    "\n",
    "# u, d, r, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_110381/263196528.py:3: RuntimeWarning: invalid value encountered in divide\n",
      "  x = (N[i]**(1/tow)) / np.sum(N[i]**(1/tow))\n"
     ]
    }
   ],
   "source": [
    "Policy = np.zeros(csrl.shape)\n",
    "for i in csrl.states():\n",
    "    x = (N[i]**(1/tow)) / np.sum(N[i]**(1/tow))\n",
    "    Policy[i] = np.nan_to_num(x)\n",
    "\n",
    "input_gws.append(channeled(csrl, enc, agent=False)[0,0,0,0].sum(0))\n",
    "policies.append(Policy[0,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(input_gws)\n",
    "y = np.array(policies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.3965 - accuracy: 0.7639\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3962 - accuracy: 0.7639\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3960 - accuracy: 0.7639\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3958 - accuracy: 0.7685\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3956 - accuracy: 0.7685\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3954 - accuracy: 0.7731\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3952 - accuracy: 0.7778\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3950 - accuracy: 0.7778\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3948 - accuracy: 0.7731\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3946 - accuracy: 0.7731\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3945 - accuracy: 0.7731\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3943 - accuracy: 0.7731\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3941 - accuracy: 0.7731\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3939 - accuracy: 0.7731\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3938 - accuracy: 0.7778\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3936 - accuracy: 0.7731\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3935 - accuracy: 0.7778\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3933 - accuracy: 0.7778\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3932 - accuracy: 0.7778\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3930 - accuracy: 0.7824\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3929 - accuracy: 0.7824\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3927 - accuracy: 0.7778\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3926 - accuracy: 0.7778\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.3924 - accuracy: 0.7778\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3923 - accuracy: 0.7731\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3922 - accuracy: 0.7685\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.3921 - accuracy: 0.7685\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.3919 - accuracy: 0.7685\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3918 - accuracy: 0.7731\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3917 - accuracy: 0.7731\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3916 - accuracy: 0.7731\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3915 - accuracy: 0.7731\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3913 - accuracy: 0.7685\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3912 - accuracy: 0.7685\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3911 - accuracy: 0.7685\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.3910 - accuracy: 0.7731\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3909 - accuracy: 0.7778\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.3908 - accuracy: 0.7731\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3907 - accuracy: 0.7685\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.3906 - accuracy: 0.7685\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3905 - accuracy: 0.7685\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3904 - accuracy: 0.7685\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.3903 - accuracy: 0.7685\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.3902 - accuracy: 0.7685\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3902 - accuracy: 0.7685\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3901 - accuracy: 0.7685\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3900 - accuracy: 0.7685\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3899 - accuracy: 0.7731\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3898 - accuracy: 0.7731\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.3897 - accuracy: 0.7731\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3896 - accuracy: 0.7731\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3896 - accuracy: 0.7731\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3895 - accuracy: 0.7639\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3894 - accuracy: 0.7639\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3893 - accuracy: 0.7593\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3893 - accuracy: 0.7593\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3892 - accuracy: 0.7593\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.3891 - accuracy: 0.7593\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.3890 - accuracy: 0.7593\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3890 - accuracy: 0.7593\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.3889 - accuracy: 0.7639\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3888 - accuracy: 0.7685\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3888 - accuracy: 0.7778\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3887 - accuracy: 0.7778\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3886 - accuracy: 0.7731\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3886 - accuracy: 0.7685\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3885 - accuracy: 0.7685\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3885 - accuracy: 0.7731\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3884 - accuracy: 0.7731\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3883 - accuracy: 0.7685\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3883 - accuracy: 0.7685\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3882 - accuracy: 0.7685\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3882 - accuracy: 0.7639\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3881 - accuracy: 0.7593\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3881 - accuracy: 0.7593\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3880 - accuracy: 0.7685\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3880 - accuracy: 0.7685\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3879 - accuracy: 0.7731\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3878 - accuracy: 0.7685\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3878 - accuracy: 0.7685\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3877 - accuracy: 0.7731\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3877 - accuracy: 0.7685\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3876 - accuracy: 0.7731\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3876 - accuracy: 0.7685\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3876 - accuracy: 0.7685\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3875 - accuracy: 0.7639\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3875 - accuracy: 0.7685\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3874 - accuracy: 0.7685\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3874 - accuracy: 0.7685\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3873 - accuracy: 0.7685\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3873 - accuracy: 0.7685\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3872 - accuracy: 0.7685\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3872 - accuracy: 0.7731\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3871 - accuracy: 0.7731\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3871 - accuracy: 0.7731\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3871 - accuracy: 0.7685\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3870 - accuracy: 0.7685\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3870 - accuracy: 0.7685\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3869 - accuracy: 0.7685\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3869 - accuracy: 0.7639\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3869 - accuracy: 0.7639\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3868 - accuracy: 0.7731\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3868 - accuracy: 0.7731\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3868 - accuracy: 0.7731\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3867 - accuracy: 0.7778\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3867 - accuracy: 0.7778\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3866 - accuracy: 0.7731\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3866 - accuracy: 0.7731\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3866 - accuracy: 0.7685\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3865 - accuracy: 0.7685\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3865 - accuracy: 0.7685\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3865 - accuracy: 0.7685\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3864 - accuracy: 0.7685\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3864 - accuracy: 0.7685\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3864 - accuracy: 0.7685\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3863 - accuracy: 0.7685\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3863 - accuracy: 0.7685\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3863 - accuracy: 0.7685\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3863 - accuracy: 0.7685\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3862 - accuracy: 0.7685\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3862 - accuracy: 0.7685\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3862 - accuracy: 0.7685\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3861 - accuracy: 0.7731\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3861 - accuracy: 0.7731\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3861 - accuracy: 0.7685\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3860 - accuracy: 0.7685\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3860 - accuracy: 0.7731\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3860 - accuracy: 0.7685\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3860 - accuracy: 0.7731\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3859 - accuracy: 0.7685\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3859 - accuracy: 0.7685\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3859 - accuracy: 0.7685\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3859 - accuracy: 0.7639\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3858 - accuracy: 0.7639\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3858 - accuracy: 0.7639\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3858 - accuracy: 0.7685\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3858 - accuracy: 0.7685\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3857 - accuracy: 0.7731\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3857 - accuracy: 0.7778\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.3857 - accuracy: 0.7639\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3857 - accuracy: 0.7593\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3856 - accuracy: 0.7593\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3856 - accuracy: 0.7593\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3856 - accuracy: 0.7639\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3856 - accuracy: 0.7639\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3855 - accuracy: 0.7593\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3855 - accuracy: 0.7593\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3855 - accuracy: 0.7593\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3855 - accuracy: 0.7593\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3855 - accuracy: 0.7593\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3854 - accuracy: 0.7593\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3854 - accuracy: 0.7593\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3854 - accuracy: 0.7639\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3854 - accuracy: 0.7593\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3854 - accuracy: 0.7593\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3853 - accuracy: 0.7500\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3853 - accuracy: 0.7593\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3853 - accuracy: 0.7546\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3853 - accuracy: 0.7546\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3853 - accuracy: 0.7546\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3852 - accuracy: 0.7593\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3852 - accuracy: 0.7500\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3852 - accuracy: 0.7546\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3852 - accuracy: 0.7593\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3852 - accuracy: 0.7593\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3851 - accuracy: 0.7639\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3851 - accuracy: 0.7593\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3851 - accuracy: 0.7546\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3851 - accuracy: 0.7500\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3851 - accuracy: 0.7500\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3850 - accuracy: 0.7500\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3850 - accuracy: 0.7500\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3850 - accuracy: 0.7546\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3850 - accuracy: 0.7593\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3850 - accuracy: 0.7639\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3850 - accuracy: 0.7500\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3849 - accuracy: 0.7546\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3849 - accuracy: 0.7546\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.3849 - accuracy: 0.7546\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3849 - accuracy: 0.7546\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3849 - accuracy: 0.7593\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.3849 - accuracy: 0.7639\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3848 - accuracy: 0.7685\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3848 - accuracy: 0.7593\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3848 - accuracy: 0.7546\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.3848 - accuracy: 0.7454\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.3848 - accuracy: 0.7500\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3848 - accuracy: 0.7454\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3848 - accuracy: 0.7454\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.3847 - accuracy: 0.7500\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3847 - accuracy: 0.7407\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3847 - accuracy: 0.7454\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3847 - accuracy: 0.7454\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3847 - accuracy: 0.7500\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3847 - accuracy: 0.7454\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3847 - accuracy: 0.7407\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3846 - accuracy: 0.7454\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.3846 - accuracy: 0.7454\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3846 - accuracy: 0.7454\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.3846 - accuracy: 0.7454\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3846 - accuracy: 0.7454\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3846 - accuracy: 0.7454\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3846 - accuracy: 0.7454\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3845 - accuracy: 0.7454\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3845 - accuracy: 0.7454\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3845 - accuracy: 0.7454\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3845 - accuracy: 0.7454\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3845 - accuracy: 0.7407\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3845 - accuracy: 0.7500\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3845 - accuracy: 0.7546\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3845 - accuracy: 0.7500\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3844 - accuracy: 0.7546\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3844 - accuracy: 0.7500\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3844 - accuracy: 0.7500\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3844 - accuracy: 0.7546\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3844 - accuracy: 0.7500\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3844 - accuracy: 0.7500\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3844 - accuracy: 0.7500\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3844 - accuracy: 0.7500\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3844 - accuracy: 0.7454\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3843 - accuracy: 0.7454\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3843 - accuracy: 0.7500\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3843 - accuracy: 0.7500\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3843 - accuracy: 0.7500\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3843 - accuracy: 0.7500\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.3843 - accuracy: 0.7500\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3843 - accuracy: 0.7500\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3843 - accuracy: 0.7454\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3843 - accuracy: 0.7454\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3842 - accuracy: 0.7454\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3842 - accuracy: 0.7500\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3842 - accuracy: 0.7546\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.3842 - accuracy: 0.7593\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3842 - accuracy: 0.7593\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3842 - accuracy: 0.7546\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3842 - accuracy: 0.7500\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3842 - accuracy: 0.7546\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3842 - accuracy: 0.7546\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3842 - accuracy: 0.7546\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3841 - accuracy: 0.7546\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3841 - accuracy: 0.7593\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3841 - accuracy: 0.7593\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3841 - accuracy: 0.7593\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3841 - accuracy: 0.7639\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3841 - accuracy: 0.7639\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3841 - accuracy: 0.7546\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3841 - accuracy: 0.7546\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3841 - accuracy: 0.7593\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3841 - accuracy: 0.7593\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3841 - accuracy: 0.7593\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3840 - accuracy: 0.7546\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.3840 - accuracy: 0.7593\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3840 - accuracy: 0.7639\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3840 - accuracy: 0.7593\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3840 - accuracy: 0.7639\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3840 - accuracy: 0.7593\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3840 - accuracy: 0.7593\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3840 - accuracy: 0.7639\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3840 - accuracy: 0.7593\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3840 - accuracy: 0.7593\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3840 - accuracy: 0.7593\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3840 - accuracy: 0.7593\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3839 - accuracy: 0.7639\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3839 - accuracy: 0.7593\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3839 - accuracy: 0.7639\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3839 - accuracy: 0.7639\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3839 - accuracy: 0.7639\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.3839 - accuracy: 0.7593\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3839 - accuracy: 0.7593\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3839 - accuracy: 0.7593\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.3839 - accuracy: 0.7639\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.3839 - accuracy: 0.7639\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.3839 - accuracy: 0.7639\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3839 - accuracy: 0.7639\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3839 - accuracy: 0.7639\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3838 - accuracy: 0.7593\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.3838 - accuracy: 0.7593\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.3838 - accuracy: 0.7546\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3838 - accuracy: 0.7593\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3838 - accuracy: 0.7593\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3838 - accuracy: 0.7639\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3838 - accuracy: 0.7639\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3838 - accuracy: 0.7639\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3838 - accuracy: 0.7639\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3838 - accuracy: 0.7593\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3838 - accuracy: 0.7593\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3838 - accuracy: 0.7639\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3838 - accuracy: 0.7593\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3838 - accuracy: 0.7546\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3838 - accuracy: 0.7546\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3837 - accuracy: 0.7593\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3837 - accuracy: 0.7593\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3837 - accuracy: 0.7593\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3837 - accuracy: 0.7639\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3837 - accuracy: 0.7639\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3837 - accuracy: 0.7639\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3837 - accuracy: 0.7593\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3837 - accuracy: 0.7639\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3837 - accuracy: 0.7639\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3837 - accuracy: 0.7639\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3837 - accuracy: 0.7593\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3837 - accuracy: 0.7593\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.3837 - accuracy: 0.7593\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3837 - accuracy: 0.7593\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3837 - accuracy: 0.7593\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3837 - accuracy: 0.7639\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3836 - accuracy: 0.7639\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3836 - accuracy: 0.7593\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3836 - accuracy: 0.7593\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3836 - accuracy: 0.7593\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3836 - accuracy: 0.7593\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3836 - accuracy: 0.7593\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3836 - accuracy: 0.7593\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3836 - accuracy: 0.7685\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3836 - accuracy: 0.7685\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3836 - accuracy: 0.7685\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3836 - accuracy: 0.7639\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/srmt/Research/Uwaterloo/RL-LTL/ComputeCanada_scrips/Scratch.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/srmt/Research/Uwaterloo/RL-LTL/ComputeCanada_scrips/Scratch.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m policy_model\u001b[39m.\u001b[39;49mfit(x, y, epochs \u001b[39m=\u001b[39;49m \u001b[39m1000\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/keras/engine/training.py:1712\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1707\u001b[0m     val_logs \u001b[39m=\u001b[39m {\n\u001b[1;32m   1708\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m val_logs\u001b[39m.\u001b[39mitems()\n\u001b[1;32m   1709\u001b[0m     }\n\u001b[1;32m   1710\u001b[0m     epoch_logs\u001b[39m.\u001b[39mupdate(val_logs)\n\u001b[0;32m-> 1712\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_epoch_end(epoch, epoch_logs)\n\u001b[1;32m   1713\u001b[0m training_logs \u001b[39m=\u001b[39m epoch_logs\n\u001b[1;32m   1714\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/keras/callbacks.py:454\u001b[0m, in \u001b[0;36mCallbackList.on_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    452\u001b[0m logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_logs(logs)\n\u001b[1;32m    453\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[0;32m--> 454\u001b[0m     callback\u001b[39m.\u001b[39;49mon_epoch_end(epoch, logs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/keras/callbacks.py:1105\u001b[0m, in \u001b[0;36mProgbarLogger.on_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_epoch_end\u001b[39m(\u001b[39mself\u001b[39m, epoch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m-> 1105\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_finalize_progbar(logs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_step)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/keras/callbacks.py:1182\u001b[0m, in \u001b[0;36mProgbarLogger._finalize_progbar\u001b[0;34m(self, logs, counter)\u001b[0m\n\u001b[1;32m   1180\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget \u001b[39m=\u001b[39m counter \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen\n\u001b[1;32m   1181\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogbar\u001b[39m.\u001b[39mtarget \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget\n\u001b[0;32m-> 1182\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprogbar\u001b[39m.\u001b[39;49mupdate(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget, \u001b[39mlist\u001b[39;49m(logs\u001b[39m.\u001b[39;49mitems()), finalize\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/keras/utils/generic_utils.py:297\u001b[0m, in \u001b[0;36mProgbar.update\u001b[0;34m(self, current, values, finalize)\u001b[0m\n\u001b[1;32m    294\u001b[0m         info \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    296\u001b[0m     message \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m info\n\u001b[0;32m--> 297\u001b[0m     io_utils\u001b[39m.\u001b[39;49mprint_msg(message, line_break\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    298\u001b[0m     message \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    300\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/keras/utils/io_utils.py:80\u001b[0m, in \u001b[0;36mprint_msg\u001b[0;34m(message, line_break)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         sys\u001b[39m.\u001b[39mstdout\u001b[39m.\u001b[39mwrite(message)\n\u001b[0;32m---> 80\u001b[0m     sys\u001b[39m.\u001b[39;49mstdout\u001b[39m.\u001b[39;49mflush()\n\u001b[1;32m     81\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     82\u001b[0m     logging\u001b[39m.\u001b[39minfo(message)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/ipykernel/iostream.py:475\u001b[0m, in \u001b[0;36mOutStream.flush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[39m\"\"\"trigger actual zmq send\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \n\u001b[1;32m    466\u001b[0m \u001b[39msend will happen in the background thread\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    469\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpub_thread\n\u001b[1;32m    470\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpub_thread\u001b[39m.\u001b[39mthread \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m ):\n\u001b[1;32m    474\u001b[0m     \u001b[39m# request flush on the background thread\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpub_thread\u001b[39m.\u001b[39;49mschedule(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flush)\n\u001b[1;32m    476\u001b[0m     \u001b[39m# wait for flush to actually get through, if we can.\u001b[39;00m\n\u001b[1;32m    477\u001b[0m     evt \u001b[39m=\u001b[39m threading\u001b[39m.\u001b[39mEvent()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/ipykernel/iostream.py:210\u001b[0m, in \u001b[0;36mIOPubThread.schedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_events\u001b[39m.\u001b[39mappend(f)\n\u001b[1;32m    209\u001b[0m     \u001b[39m# wake event thread (message content is ignored)\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event_pipe\u001b[39m.\u001b[39;49msend(\u001b[39mb\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    211\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    212\u001b[0m     f()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/zmq/sugar/socket.py:688\u001b[0m, in \u001b[0;36mSocket.send\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    681\u001b[0m         data \u001b[39m=\u001b[39m zmq\u001b[39m.\u001b[39mFrame(\n\u001b[1;32m    682\u001b[0m             data,\n\u001b[1;32m    683\u001b[0m             track\u001b[39m=\u001b[39mtrack,\n\u001b[1;32m    684\u001b[0m             copy\u001b[39m=\u001b[39mcopy \u001b[39mor\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    685\u001b[0m             copy_threshold\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy_threshold,\n\u001b[1;32m    686\u001b[0m         )\n\u001b[1;32m    687\u001b[0m     data\u001b[39m.\u001b[39mgroup \u001b[39m=\u001b[39m group\n\u001b[0;32m--> 688\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49msend(data, flags\u001b[39m=\u001b[39;49mflags, copy\u001b[39m=\u001b[39;49mcopy, track\u001b[39m=\u001b[39;49mtrack)\n",
      "File \u001b[0;32mzmq/backend/cython/socket.pyx:742\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mzmq/backend/cython/socket.pyx:789\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mzmq/backend/cython/socket.pyx:250\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/zmq/backend/cython/checkrc.pxd:13\u001b[0m, in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "policy_model.fit(x, y, epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_policy = policy_model(channeled(csrl, enc, agent=False)[0,0,0,0].sum(0).reshape(1,3,3))\n",
    "# pred_policy = policy_model(input_gws[4].reshape(1,3,3))\n",
    "\n",
    "pred_policy = np.argmax(pred_policy[0,0], 2)\n",
    "pred_policy = np.where(pred_policy == 0, '^', pred_policy)\n",
    "pred_policy = np.where(pred_policy == '1', 'v', pred_policy)\n",
    "pred_policy = np.where(pred_policy == '2', '>', pred_policy)\n",
    "pred_policy = np.where(pred_policy == '3', '<', pred_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2., 0., 3.],\n",
       "        [0., 4., 0.],\n",
       "        [0., 0., 0.]]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channeled(csrl, enc, agent=False)[0,0,0,0].sum(0).reshape(1,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['5', '>', '6'],\n",
       "       ['>', '^', '^'],\n",
       "       ['^', '^', '<']], dtype='<U21')"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[2., 0., 3.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 4., 0.]]),\n",
       " array([[2., 0., 3.],\n",
       "        [0., 0., 0.],\n",
       "        [4., 0., 0.]]),\n",
       " array([[2., 0., 3.],\n",
       "        [4., 0., 0.],\n",
       "        [0., 0., 0.]]),\n",
       " array([[2., 0., 3.],\n",
       "        [0., 0., 4.],\n",
       "        [0., 0., 0.]]),\n",
       " array([[2., 4., 3.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]]),\n",
       " array([[2., 0., 3.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 4.]])]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_gws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? 0.6\n",
      "0 ) MCTS conf: 0.17 , det: 1.0 | ? 1\n",
      "LTL [+++]  LDBA [ 0.01 ] path: [3, 0, 0]\n",
      "? 0.05260303\n",
      "? 1\n",
      "1 ) MCTS conf: 0.96 , det: 1.0 | ? 1\n",
      "LTL [+++]  LDBA [ 0.01 ] path: [5, 2, 2]\n",
      "? 0.06288229\n",
      "? 0.9939205570480697\n",
      "? 1\n",
      "2 ) MCTS conf: 0.99 , det: 1.0 | LTL [+++]  LDBA [ 0.01 ] path: [6, 3, 0, 0]\n",
      "? 0.0014226277\n",
      "? 1\n",
      "3 ) MCTS conf: 0.99 , det: 1.0 | LTL [+++]  LDBA [ 0.01 ] path: [8, 5, 2, 2]\n",
      "? 0.34072602\n",
      "? 0.37543768\n",
      "? 0.3911557\n",
      "? 1\n",
      "4 ) MCTS conf: 0.22 , det: 1.0 | LTL [+++]  LDBA [ 0.01 ] path: [7, 6, 3, 0, 0]\n",
      "5 ) MCTS conf: 1.0 , det: 1.0 | LTL [+++]  LDBA [ 0.01 ] path: [5, 2, 2]\n",
      "6 ) MCTS conf: 1.0 , det: 1.0 | LTL [+++]  LDBA [ 0.01 ] path: [7, 6, 3, 0, 0]\n",
      "7 ) MCTS conf: 0.99 , det: 1.0 | LTL [+++]  LDBA [ 0.01 ] path: [7, 6, 3, 0, 0]\n",
      "8 ) MCTS conf: 0.19 , det: 1.0 | LTL [+++]  LDBA [ 0.01 ] path: [3, 0, 0]\n",
      "9 ) MCTS conf: 1.0 , det: 1.0 | LTL [+++]  LDBA [ 0.01 ] path: [5, 2, 2]\n",
      "Train wins: 10 / 10\n",
      "? 0.31173742\n",
      "? 0.32700434\n",
      "? 1\n",
      "None ) MCTS conf: 0.8 , det: 0.7 | LTL [+++]  LDBA [ 0.01 ] path: [1, 0, 0]\n",
      "None ) MCTS conf: 0.96 , det: 1.0 | LTL [+++]  LDBA [ 0.01 ] path: [8, 5, 2, 2]\n",
      "None ) MCTS conf: 0.18 , det: 1.0 | LTL [+++]  LDBA [ 0.01 ] path: [3, 0, 0]\n",
      "None ) MCTS conf: 1.0 , det: 1.0 | LTL [+++]  LDBA [ 0.01 ] path: [8, 5, 2, 2]\n",
      "None ) MCTS conf: 0.97 , det: 0.99 | LTL [+++]  LDBA [ 0.01 ] path: [7, 6, 3, 0, 0]\n",
      "None ) MCTS conf: 1.0 , det: 1.0 | LTL [+++]  LDBA [ 0.01 ] path: [8, 5, 2, 2]\n",
      "None ) MCTS conf: 1.0 , det: 1.0 | LTL [+++]  LDBA [ 0.01 ] path: [6, 3, 0, 0]\n",
      "None ) MCTS conf: 1.0 , det: 1.0 | LTL [+++]  LDBA [ 0.01 ] path: [5, 2, 2]\n",
      "None ) MCTS conf: 1.0 , det: 1.0 | LTL [+++]  LDBA [ 0.01 ] path: [8, 5, 2, 2]\n",
      "None ) MCTS conf: 1.0 , det: 0.99 | LTL [+++]  LDBA [ 0.01 ] path: [7, 6, 3, 0, 0]\n",
      "Test wins: 10 / 10\n"
     ]
    }
   ],
   "source": [
    "visited_states_train = []\n",
    "visited_states_test = []\n",
    "LTL_coef = 10\n",
    "NN_value_active = False\n",
    "\n",
    "search_depth = 100\n",
    "MCTS_samples = 100\n",
    "\n",
    "num_training_epochs =  10\n",
    "num_test_epochs = 10\n",
    "training = True\n",
    "epochs = 10\n",
    "C = 1\n",
    "tow = 0.1\n",
    "T = [25]\n",
    "K = 1\n",
    "batch_size = 32\n",
    "steps_per_epoch = 4\n",
    "idx = 0\n",
    "success_rates = []\n",
    "succes_std = []\n",
    "win_hist = []\n",
    "train_history = []\n",
    "\n",
    "best_val_len = {}\n",
    "for s in csrl.states(): best_val_len[s] = (0.001, 99999)\n",
    "\n",
    "# os.remove(\"Log_run.txt\")\n",
    "for i in T:\n",
    "    idx += 1\n",
    "    # TRAIN ##############################\n",
    "    train_wins = 0\n",
    "    # num_training_epochs = int(200 - 1.9*i)\n",
    "    # model = build_model(ch_states[(0,0,0,0)].shape, csrl.shape[-1])\n",
    "    N, W, Q, P, visited_train = np.zeros(csrl.shape), np.zeros(csrl.shape), np.zeros(csrl.shape), np.zeros(csrl.shape), set()\n",
    "    for epoch in range(num_training_epochs):\n",
    "        t1 = time.time()\n",
    "        state_history, channeled_states, trajectory, action_history, reward_history, better_policy, best_val_len = MC_learning(csrl, model, LTL_formula,\n",
    "                predicates, csrl.reward, ch_states, N = N, W = W, Q = Q, P = P, C=C, tow=tow, n_samples=MCTS_samples, visited=visited_train,\n",
    "                start=None, search_depth=search_depth, verbose=0, T=i, K=K, NN_value_active=NN_value_active, run_num=epoch, ltl_f_rew=False, reachability=True, \n",
    "                best_val_len = best_val_len)\n",
    "        # print(\"!\", best_val_len[(0,0,0,0)])\n",
    "        visited_states_train += state_history\n",
    "        t2 = time.time()\n",
    "        # print(t2-t1, \" run episode\")\n",
    "\n",
    "        # win = check_LTL(LTL_formula, trajectory, predicates)[0]\n",
    "        if reward_history[-1]>0:\n",
    "            train_wins+=1\n",
    "            NN_value_active = True\n",
    "\n",
    "        if training and len(action_history)>0:\n",
    "            if epoch==0:\n",
    "                x_train = np.array(channeled_states)[:-1]\n",
    "                y1_train = np.array(better_policy)\n",
    "                y2_train = np.array(reward_history) + LTL_coef*reward_history[-1]\n",
    "                # y2_train = np.array(reward_history)\n",
    "                y2_train = y2_train[:-1]\n",
    "            else:\n",
    "                x_train = np.concatenate((x_train, np.array(channeled_states)[:-1]),0)\n",
    "                y1_train = np.concatenate((y1_train, np.array(better_policy)),0)\n",
    "                y2_train_curr = np.array(reward_history) + LTL_coef*reward_history[-1]\n",
    "                # y2_train_curr = np.array(reward_history)\n",
    "                y2_train = np.concatenate((y2_train, y2_train_curr[:-1]),0)\n",
    "            t3= time.time()\n",
    "            # print(t3-t2, \" build database\")\n",
    "            tr_hist = model.fit(x_train, [y1_train, y2_train], epochs=epochs, batch_size=batch_size,\n",
    "                                steps_per_epoch=steps_per_epoch if len(x_train)>steps_per_epoch*epochs*batch_size else None, verbose=0)\n",
    "            train_history += tr_hist.history['loss']\n",
    "        # win_hist.append(win)\n",
    "        t4 = time.time()\n",
    "        # print(t4-t3, \"fit\", len(x_train))\n",
    "    print(\"Train wins:\",train_wins,\"/\", num_training_epochs)\n",
    "\n",
    "    # TEST ##############################\n",
    "    test_wins = 0\n",
    "    N, W, Q, P, visited_test = np.zeros(csrl.shape), np.zeros(csrl.shape), np.zeros(csrl.shape), np.zeros(csrl.shape), set()\n",
    "    for epoch in range(num_test_epochs):\n",
    "        \n",
    "        state_history, channeled_states, trajectory, action_history, reward_history, better_policy, best_val_len = MC_learning(csrl, model, LTL_formula,\n",
    "                predicates, csrl.reward, ch_states, N = N, W = W, Q = Q, P = P, C=1, tow=1, n_samples=MCTS_samples, visited=visited_test,\n",
    "                start=None, search_depth=search_depth, verbose=0, T=i, K=1, NN_value_active=True, reachability=True, best_val_len = best_val_len)\n",
    "\n",
    "        # win = check_LTL(LTL_formula, trajectory, predicates)[0]\n",
    "        win = reward_history[-1]\n",
    "        if win: test_wins+=1\n",
    "        win_hist.append(win)\n",
    "        visited_states_test += state_history\n",
    "        \n",
    "    success_rates.append(100*test_wins/num_test_epochs)\n",
    "    temp = np.zeros(num_test_epochs)\n",
    "    temp[:test_wins]=1\n",
    "    std = np.sqrt(num_test_epochs*np.var(temp))\n",
    "    succes_std.append((success_rates[-1]-std, success_rates[-1]+std))\n",
    "    \n",
    "    ###############################################################\n",
    "    print(\"Test wins:\",test_wins,\"/\",num_test_epochs)\n",
    "    # print(\"last reward:\", reward_history[-1], \"  | trajectory:\", trajectory)\n",
    "    # print(\"Actions:\", action_history)\n",
    "\n",
    "encode_visited_states_test = [i[1]*csrl.shape[-2]*csrl.shape[-3]+i[2]*csrl.shape[-2]+i[3] for i in visited_states_test]\n",
    "encode_visited_states_train = [i[1]*csrl.shape[-2]*csrl.shape[-3]+i[2]*csrl.shape[-2]+i[3] for i in visited_states_train]\n",
    "\n",
    "# u, d, r, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20664/263196528.py:3: RuntimeWarning: invalid value encountered in divide\n",
      "  x = (N[i]**(1/tow)) / np.sum(N[i]**(1/tow))\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_val_len ????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
