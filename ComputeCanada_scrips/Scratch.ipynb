{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Safe Absorbing States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-06 17:10:12.693301: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from NN import *\n",
    "from LTL import *\n",
    "from Utility_funcs import *\n",
    "\n",
    "%matplotlib inline\n",
    "from csrl.mdp import GridMDP\n",
    "from csrl.oa import OmegaAutomaton\n",
    "from csrl import ControlSynthesis\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_gws = []\n",
    "policies = []\n",
    "\n",
    "# policy_model = build_policy_model(channeled(csrl, enc, agent=False)[0,0,0,0].sum(0).shape, Policy[0,:,:,:].shape)\n",
    "policy_model = build_policy_model((3,3), (4, 3, 3, 8))\n",
    "policy_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Omega-automaton states (including the trap state): 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<csrl.oa.OmegaAutomaton at 0x7fc8a2c96af0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# LTL Specification\n",
    "ltl = '(F G a | F G b) & G !d'\n",
    "\n",
    "# Translate the LTL formula to an LDBA\n",
    "oa = OmegaAutomaton(ltl)\n",
    "print('Number of Omega-automaton states (including the trap state):',oa.shape[1])\n",
    "display(oa)\n",
    "\n",
    "# MDP Description\n",
    "shape = (3,3)\n",
    "# E: Empty, T: Trap, B: Obstacle\n",
    "structure = np.array([\n",
    "['E',  'E',  'E'],\n",
    "['E',  'E',  'E'],\n",
    "['E',  'E',  'E'],\n",
    "])\n",
    "\n",
    "# Labels of the states\n",
    "label = np.array([\n",
    "[('a',),(),('b',)],\n",
    "[(),('d',),    ()],\n",
    "[(),    (),    ()],\n",
    "],dtype=object)\n",
    "# Colors of the labels\n",
    "lcmap={\n",
    "    ('a',):'lightgreen',\n",
    "    ('b',):'lightgreen',\n",
    "    ('d',):'pink'\n",
    "}\n",
    "p = 1\n",
    "grid_mdp = GridMDP(shape=shape,structure=structure,label=label,lcmap=lcmap, p=p, figsize=5)  # Use figsize=4 for smaller figures\n",
    "grid_mdp.plot()\n",
    "\n",
    "# Construct the product MDP\n",
    "csrl = ControlSynthesis(grid_mdp,oa)\n",
    "max_rew = round(csrl.reward.max(), 3)\n",
    "\n",
    "s_vectors = state_vectors(csrl)\n",
    "enc = list(np.unique(grid_mdp.label))\n",
    "enc.pop(enc.index(()))\n",
    "ch_states = channeled(csrl, enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': [0], 'b': [2], 'd': [4]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_t = \"(<> [] a \\/ <> [] b) /\\ [] ~d\"\n",
    "\n",
    "LTL_formula = parser.parse(full_t)\n",
    "predicates=get_predicates(grid_mdp)\n",
    "predicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-06 17:10:17.890165: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-06 17:10:17.890565: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 3, 3, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 3, 3, 32)     544         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 3, 3, 8)      1032        ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 72)           0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 32)           2336        ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 16)           528         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 8)            136         ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1)            17          ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,593\n",
      "Trainable params: 4,593\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(ch_states[(0,0,0,0)].shape, csrl.shape[-1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ) MCTS conf: -0.16 , det: 0.99 | LTL [+++]  LDBA [ 0.01 ] path: [1, 0, 0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/srmt/Research/Uwaterloo/RL-LTL/ComputeCanada_scrips/Scratch.ipynb Cell 7\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/srmt/Research/Uwaterloo/RL-LTL/ComputeCanada_scrips/Scratch.ipynb#X13sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m             y2_train_curr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(reward_history) \u001b[39m+\u001b[39m LTL_coef\u001b[39m*\u001b[39mreward_history[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/srmt/Research/Uwaterloo/RL-LTL/ComputeCanada_scrips/Scratch.ipynb#X13sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m             y2_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((y2_train, y2_train_curr[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]),\u001b[39m0\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/srmt/Research/Uwaterloo/RL-LTL/ComputeCanada_scrips/Scratch.ipynb#X13sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m         tr_hist \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(x_train, [y1_train, y2_train], epochs\u001b[39m=\u001b[39;49mepochs, batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/srmt/Research/Uwaterloo/RL-LTL/ComputeCanada_scrips/Scratch.ipynb#X13sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m                             steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch \u001b[39mif\u001b[39;49;00m \u001b[39mlen\u001b[39;49m(x_train)\u001b[39m>\u001b[39;49msteps_per_epoch\u001b[39m*\u001b[39;49mepochs\u001b[39m*\u001b[39;49mbatch_size \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/srmt/Research/Uwaterloo/RL-LTL/ComputeCanada_scrips/Scratch.ipynb#X13sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m         train_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_hist\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/srmt/Research/Uwaterloo/RL-LTL/ComputeCanada_scrips/Scratch.ipynb#X13sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTrain wins:\u001b[39m\u001b[39m\"\u001b[39m,train_wins,\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m, num_training_epochs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1651\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:945\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    941\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[1;32m    942\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    943\u001b[0m     \u001b[39m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[1;32m    944\u001b[0m     \u001b[39m# no_variable_creation function.\u001b[39;00m\n\u001b[0;32m--> 945\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    946\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    947\u001b[0m   _, _, filtered_flat_args \u001b[39m=\u001b[39m (\n\u001b[1;32m    948\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn\u001b[39m.\u001b[39m_function_spec  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    949\u001b[0m       \u001b[39m.\u001b[39mcanonicalize_function_inputs(\n\u001b[1;32m    950\u001b[0m           args, kwds))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:133\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[0;32m--> 133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[1;32m    134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39m_call_flat(\n\u001b[1;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39mconcrete_function\u001b[39m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:360\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m   \u001b[39m# Only get placeholders for arguments, not captures\u001b[39;00m\n\u001b[1;32m    358\u001b[0m   args, kwargs \u001b[39m=\u001b[39m generalized_func_key\u001b[39m.\u001b[39m_placeholder_value()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 360\u001b[0m concrete_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_concrete_function(args, kwargs)\n\u001b[1;32m    362\u001b[0m graph_capture_container \u001b[39m=\u001b[39m concrete_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39m_capture_func_lib  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[39m# Maintain the list of all captures\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:284\u001b[0m, in \u001b[0;36mTracingCompiler._create_concrete_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[1;32m    280\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m    281\u001b[0m ]\n\u001b[1;32m    282\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[1;32m    283\u001b[0m concrete_function \u001b[39m=\u001b[39m monomorphic_function\u001b[39m.\u001b[39mConcreteFunction(\n\u001b[0;32m--> 284\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[1;32m    285\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[1;32m    286\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[1;32m    287\u001b[0m         args,\n\u001b[1;32m    288\u001b[0m         kwargs,\n\u001b[1;32m    289\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    290\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[1;32m    291\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[1;32m    292\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[1;32m    293\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[1;32m    294\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[1;32m    295\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[1;32m    296\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m    297\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m    298\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m    299\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m    300\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    301\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1283\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1280\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1281\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1283\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[1;32m   1285\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1286\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1287\u001b[0m func_outputs \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:645\u001b[0m, in \u001b[0;36mFunction._compiler_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[39mwith\u001b[39;00m default_graph\u001b[39m.\u001b[39m_variable_creator_scope(scope, priority\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    642\u001b[0m   \u001b[39m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    643\u001b[0m   \u001b[39m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    644\u001b[0m   \u001b[39mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 645\u001b[0m     out \u001b[39m=\u001b[39m weak_wrapped_fn()\u001b[39m.\u001b[39;49m__wrapped__(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    646\u001b[0m   \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1258\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[39m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[39;00m\n\u001b[1;32m   1257\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1258\u001b[0m   \u001b[39mreturn\u001b[39;00m autograph\u001b[39m.\u001b[39;49mconverted_call(\n\u001b[1;32m   1259\u001b[0m       original_func,\n\u001b[1;32m   1260\u001b[0m       args,\n\u001b[1;32m   1261\u001b[0m       kwargs,\n\u001b[1;32m   1262\u001b[0m       options\u001b[39m=\u001b[39;49mautograph\u001b[39m.\u001b[39;49mConversionOptions(\n\u001b[1;32m   1263\u001b[0m           recursive\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1264\u001b[0m           optional_features\u001b[39m=\u001b[39;49mautograph_options,\n\u001b[1;32m   1265\u001b[0m           user_requested\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1266\u001b[0m       ))\n\u001b[1;32m   1267\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1268\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39;49meffective_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filefbs5t2e8.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(step_function), (ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m), ag__\u001b[39m.\u001b[39;49mld(iterator)), \u001b[39mNone\u001b[39;49;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[39mif\u001b[39;00m conversion\u001b[39m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[1;32m    330\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: from cache\u001b[39m\u001b[39m'\u001b[39m, f)\n\u001b[0;32m--> 331\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    333\u001b[0m \u001b[39mif\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mcontrol_status_ctx()\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m ag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mDISABLED:\n\u001b[1;32m    334\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: AutoGraph is disabled in context\u001b[39m\u001b[39m'\u001b[39m, f)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/keras/engine/training.py:1233\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1229\u001b[0m     run_step \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mfunction(\n\u001b[1;32m   1230\u001b[0m         run_step, jit_compile\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, reduce_retracing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1231\u001b[0m     )\n\u001b[1;32m   1232\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(iterator)\n\u001b[0;32m-> 1233\u001b[0m outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mdistribute_strategy\u001b[39m.\u001b[39;49mrun(run_step, args\u001b[39m=\u001b[39;49m(data,))\n\u001b[1;32m   1234\u001b[0m outputs \u001b[39m=\u001b[39m reduce_per_replica(\n\u001b[1;32m   1235\u001b[0m     outputs,\n\u001b[1;32m   1236\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy,\n\u001b[1;32m   1237\u001b[0m     reduction\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_reduction_method,\n\u001b[1;32m   1238\u001b[0m )\n\u001b[1;32m   1239\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1316\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1311\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscope():\n\u001b[1;32m   1312\u001b[0m   \u001b[39m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[1;32m   1313\u001b[0m   \u001b[39m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[1;32m   1314\u001b[0m   fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[1;32m   1315\u001b[0m       fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m-> 1316\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extended\u001b[39m.\u001b[39;49mcall_for_each_replica(fn, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2895\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2893\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m   2894\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy()\u001b[39m.\u001b[39mscope():\n\u001b[0;32m-> 2895\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_for_each_replica(fn, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3696\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3694\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_for_each_replica\u001b[39m(\u001b[39mself\u001b[39m, fn, args, kwargs):\n\u001b[1;32m   3695\u001b[0m   \u001b[39mwith\u001b[39;00m ReplicaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[0;32m-> 3696\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/keras/engine/training.py:1222\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1221\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_step\u001b[39m(data):\n\u001b[0;32m-> 1222\u001b[0m     outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrain_step(data)\n\u001b[1;32m   1223\u001b[0m     \u001b[39m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[1;32m   1224\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/keras/engine/training.py:1027\u001b[0m, in \u001b[0;36mModel.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_target_and_loss(y, loss)\n\u001b[1;32m   1026\u001b[0m \u001b[39m# Run backwards pass.\u001b[39;00m\n\u001b[0;32m-> 1027\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer\u001b[39m.\u001b[39;49mminimize(loss, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainable_variables, tape\u001b[39m=\u001b[39;49mtape)\n\u001b[1;32m   1028\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_metrics(x, y, y_pred, sample_weight)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py:527\u001b[0m, in \u001b[0;36m_BaseOptimizer.minimize\u001b[0;34m(self, loss, var_list, tape)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[39m\"\"\"Minimize `loss` by updating `var_list`.\u001b[39;00m\n\u001b[1;32m    507\u001b[0m \n\u001b[1;32m    508\u001b[0m \u001b[39mThis method simply computes gradient using `tf.GradientTape` and calls\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[39m  None\u001b[39;00m\n\u001b[1;32m    525\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    526\u001b[0m grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_gradients(loss, var_list, tape)\n\u001b[0;32m--> 527\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_gradients(grads_and_vars)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py:1140\u001b[0m, in \u001b[0;36mOptimizer.apply_gradients\u001b[0;34m(self, grads_and_vars, name, skip_gradients_aggregation, **kwargs)\u001b[0m\n\u001b[1;32m   1138\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m skip_gradients_aggregation \u001b[39mand\u001b[39;00m experimental_aggregate_gradients:\n\u001b[1;32m   1139\u001b[0m     grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maggregate_gradients(grads_and_vars)\n\u001b[0;32m-> 1140\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mapply_gradients(grads_and_vars, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py:634\u001b[0m, in \u001b[0;36m_BaseOptimizer.apply_gradients\u001b[0;34m(self, grads_and_vars, name)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_weight_decay(trainable_variables)\n\u001b[1;32m    633\u001b[0m grads_and_vars \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(grads, trainable_variables))\n\u001b[0;32m--> 634\u001b[0m iteration \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_internal_apply_gradients(grads_and_vars)\n\u001b[1;32m    636\u001b[0m \u001b[39m# Apply variable constraints after applying gradients.\u001b[39;00m\n\u001b[1;32m    637\u001b[0m \u001b[39mfor\u001b[39;00m variable \u001b[39min\u001b[39;00m trainable_variables:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py:1166\u001b[0m, in \u001b[0;36mOptimizer._internal_apply_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_internal_apply_gradients\u001b[39m(\u001b[39mself\u001b[39m, grads_and_vars):\n\u001b[0;32m-> 1166\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49m__internal__\u001b[39m.\u001b[39;49mdistribute\u001b[39m.\u001b[39;49minterim\u001b[39m.\u001b[39;49mmaybe_merge_call(\n\u001b[1;32m   1167\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_distributed_apply_gradients_fn,\n\u001b[1;32m   1168\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_distribution_strategy,\n\u001b[1;32m   1169\u001b[0m         grads_and_vars,\n\u001b[1;32m   1170\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/distribute/merge_call_interim.py:51\u001b[0m, in \u001b[0;36mmaybe_merge_call\u001b[0;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39m\"\"\"Maybe invoke `fn` via `merge_call` which may or may not be fulfilled.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[39mThe caller of this utility function requests to invoke `fn` via `merge_call`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39m  The return value of the `fn` call.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[39mif\u001b[39;00m strategy_supports_no_merge_call():\n\u001b[0;32m---> 51\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(strategy, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   \u001b[39mreturn\u001b[39;00m distribution_strategy_context\u001b[39m.\u001b[39mget_replica_context()\u001b[39m.\u001b[39mmerge_call(\n\u001b[1;32m     54\u001b[0m       fn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py:1216\u001b[0m, in \u001b[0;36mOptimizer._distributed_apply_gradients_fn\u001b[0;34m(self, distribution, grads_and_vars, **kwargs)\u001b[0m\n\u001b[1;32m   1213\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_step(grad, var)\n\u001b[1;32m   1215\u001b[0m \u001b[39mfor\u001b[39;00m grad, var \u001b[39min\u001b[39;00m grads_and_vars:\n\u001b[0;32m-> 1216\u001b[0m     distribution\u001b[39m.\u001b[39;49mextended\u001b[39m.\u001b[39;49mupdate(\n\u001b[1;32m   1217\u001b[0m         var, apply_grad_to_update_var, args\u001b[39m=\u001b[39;49m(grad,), group\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m     )\n\u001b[1;32m   1220\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_ema:\n\u001b[1;32m   1221\u001b[0m     _, var_list \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mgrads_and_vars)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2639\u001b[0m, in \u001b[0;36mStrategyExtendedV2.update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2637\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update(var, fn, args, kwargs, group)\n\u001b[1;32m   2638\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2639\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_replica_ctx_update(\n\u001b[1;32m   2640\u001b[0m       var, fn, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs, group\u001b[39m=\u001b[39;49mgroup)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2518\u001b[0m, in \u001b[0;36mStrategyExtendedV2._replica_ctx_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2515\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge_fn\u001b[39m(_, \u001b[39m*\u001b[39mmerged_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmerged_kwargs):\n\u001b[1;32m   2516\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate(var, fn, merged_args, merged_kwargs, group\u001b[39m=\u001b[39mgroup)\n\u001b[0;32m-> 2518\u001b[0m \u001b[39mreturn\u001b[39;00m replica_context\u001b[39m.\u001b[39;49mmerge_call(merge_fn, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3110\u001b[0m, in \u001b[0;36mReplicaContextBase.merge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3106\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m   3108\u001b[0m merge_fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[1;32m   3109\u001b[0m     merge_fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m-> 3110\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_merge_call(merge_fn, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3117\u001b[0m, in \u001b[0;36mReplicaContextBase._merge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3114\u001b[0m _push_per_thread_mode(  \u001b[39m# thread-local, so not needed with multiple threads\u001b[39;00m\n\u001b[1;32m   3115\u001b[0m     distribution_strategy_context\u001b[39m.\u001b[39m_CrossReplicaThreadMode(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_strategy))  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   3116\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3117\u001b[0m   \u001b[39mreturn\u001b[39;00m merge_fn(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_strategy, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   3118\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   3119\u001b[0m   _pop_per_thread_mode()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2516\u001b[0m, in \u001b[0;36mStrategyExtendedV2._replica_ctx_update.<locals>.merge_fn\u001b[0;34m(_, *merged_args, **merged_kwargs)\u001b[0m\n\u001b[1;32m   2515\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge_fn\u001b[39m(_, \u001b[39m*\u001b[39mmerged_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmerged_kwargs):\n\u001b[0;32m-> 2516\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate(var, fn, merged_args, merged_kwargs, group\u001b[39m=\u001b[39;49mgroup)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2637\u001b[0m, in \u001b[0;36mStrategyExtendedV2.update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2634\u001b[0m   fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[1;32m   2635\u001b[0m       fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   2636\u001b[0m   \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy()\u001b[39m.\u001b[39mscope():\n\u001b[0;32m-> 2637\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update(var, fn, args, kwargs, group)\n\u001b[1;32m   2638\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2639\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_replica_ctx_update(\n\u001b[1;32m   2640\u001b[0m       var, fn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs, group\u001b[39m=\u001b[39mgroup)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3710\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   3707\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update\u001b[39m(\u001b[39mself\u001b[39m, var, fn, args, kwargs, group):\n\u001b[1;32m   3708\u001b[0m   \u001b[39m# The implementations of _update() and _update_non_slot() are identical\u001b[39;00m\n\u001b[1;32m   3709\u001b[0m   \u001b[39m# except _update() passes `var` as the first argument to `fn()`.\u001b[39;00m\n\u001b[0;32m-> 3710\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_non_slot(var, fn, (var,) \u001b[39m+\u001b[39;49m \u001b[39mtuple\u001b[39;49m(args), kwargs, group)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3716\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   3712\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_non_slot\u001b[39m(\u001b[39mself\u001b[39m, colocate_with, fn, args, kwargs, should_group):\n\u001b[1;32m   3713\u001b[0m   \u001b[39m# TODO(josh11b): Figure out what we should be passing to UpdateContext()\u001b[39;00m\n\u001b[1;32m   3714\u001b[0m   \u001b[39m# once that value is used for something.\u001b[39;00m\n\u001b[1;32m   3715\u001b[0m   \u001b[39mwith\u001b[39;00m UpdateContext(colocate_with):\n\u001b[0;32m-> 3716\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   3717\u001b[0m     \u001b[39mif\u001b[39;00m should_group:\n\u001b[1;32m   3718\u001b[0m       \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[1;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[39mif\u001b[39;00m conversion\u001b[39m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[1;32m    330\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: from cache\u001b[39m\u001b[39m'\u001b[39m, f)\n\u001b[0;32m--> 331\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    333\u001b[0m \u001b[39mif\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mcontrol_status_ctx()\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m ag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mDISABLED:\n\u001b[1;32m    334\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: AutoGraph is disabled in context\u001b[39m\u001b[39m'\u001b[39m, f)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py:1213\u001b[0m, in \u001b[0;36mOptimizer._distributed_apply_gradients_fn.<locals>.apply_grad_to_update_var\u001b[0;34m(var, grad)\u001b[0m\n\u001b[1;32m   1211\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_step_xla(grad, var, \u001b[39mid\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_var_key(var)))\n\u001b[1;32m   1212\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1213\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_step(grad, var)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/optimizer.py:224\u001b[0m, in \u001b[0;36m_BaseOptimizer._update_step\u001b[0;34m(self, gradient, variable)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_var_key(variable) \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_dict:\n\u001b[1;32m    216\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\n\u001b[1;32m    217\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe optimizer cannot recognize variable \u001b[39m\u001b[39m{\u001b[39;00mvariable\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    218\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThis usually means you are trying to call the optimizer to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`tf.keras.optimizers.legacy.\u001b[39m\u001b[39m{self.__class__.__name__}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    223\u001b[0m     )\n\u001b[0;32m--> 224\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate_step(gradient, variable)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/keras/optimizers/optimizer_experimental/adam.py:170\u001b[0m, in \u001b[0;36mAdam.update_step\u001b[0;34m(self, gradient, variable)\u001b[0m\n\u001b[1;32m    167\u001b[0m m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_momentums[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_dict[var_key]]\n\u001b[1;32m    168\u001b[0m v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_velocities[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_dict[var_key]]\n\u001b[0;32m--> 170\u001b[0m alpha \u001b[39m=\u001b[39m lr \u001b[39m*\u001b[39m tf\u001b[39m.\u001b[39msqrt(\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta_2_power) \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39;49m \u001b[39m-\u001b[39;49m beta_1_power)\n\u001b[1;32m    172\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(gradient, tf\u001b[39m.\u001b[39mIndexedSlices):\n\u001b[1;32m    173\u001b[0m     \u001b[39m# Sparse gradients.\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     m\u001b[39m.\u001b[39massign_add(\u001b[39m-\u001b[39mm \u001b[39m*\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbeta_1))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py:1442\u001b[0m, in \u001b[0;36m_OverrideBinaryOperatorHelper.<locals>.r_binary_op_wrapper\u001b[0;34m(y, x)\u001b[0m\n\u001b[1;32m   1438\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(\u001b[39mNone\u001b[39;00m, op_name, [x, y]) \u001b[39mas\u001b[39;00m name:\n\u001b[1;32m   1439\u001b[0m   \u001b[39m# TODO(b/178860388): Figure out why binary_op_wrapper and\u001b[39;00m\n\u001b[1;32m   1440\u001b[0m   \u001b[39m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[39;00m\n\u001b[1;32m   1441\u001b[0m   y, x \u001b[39m=\u001b[39m maybe_promote_tensors(y, x, force_same_dtype\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m-> 1442\u001b[0m   \u001b[39mreturn\u001b[39;00m func(x, y, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py:548\u001b[0m, in \u001b[0;36msubtract\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mmath.subtract\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msubtract\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    545\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39mregister_binary_elementwise_api\n\u001b[1;32m    546\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[1;32m    547\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msubtract\u001b[39m(x, y, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 548\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_math_ops\u001b[39m.\u001b[39;49msub(x, y, name)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py:11176\u001b[0m, in \u001b[0;36msub\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m  11174\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[1;32m  11175\u001b[0m \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[0;32m> 11176\u001b[0m _, _, _op, _outputs \u001b[39m=\u001b[39m _op_def_library\u001b[39m.\u001b[39;49m_apply_op_helper(\n\u001b[1;32m  11177\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mSub\u001b[39;49m\u001b[39m\"\u001b[39;49m, x\u001b[39m=\u001b[39;49mx, y\u001b[39m=\u001b[39;49my, name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m  11178\u001b[0m _result \u001b[39m=\u001b[39m _outputs[:]\n\u001b[1;32m  11179\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py:795\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    790\u001b[0m must_colocate_inputs \u001b[39m=\u001b[39m [val \u001b[39mfor\u001b[39;00m arg, val \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(op_def\u001b[39m.\u001b[39minput_arg, inputs)\n\u001b[1;32m    791\u001b[0m                         \u001b[39mif\u001b[39;00m arg\u001b[39m.\u001b[39mis_ref]\n\u001b[1;32m    792\u001b[0m \u001b[39mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[1;32m    793\u001b[0m   \u001b[39m# Add Op to graph\u001b[39;00m\n\u001b[1;32m    794\u001b[0m   \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 795\u001b[0m   op \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39;49m_create_op_internal(op_type_name, inputs, dtypes\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    796\u001b[0m                              name\u001b[39m=\u001b[39;49mscope, input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[1;32m    797\u001b[0m                              attrs\u001b[39m=\u001b[39;49mattr_protos, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[1;32m    799\u001b[0m \u001b[39m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[1;32m    800\u001b[0m \u001b[39m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[39m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[39m# for more details.\u001b[39;00m\n\u001b[1;32m    803\u001b[0m outputs \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39moutputs\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:749\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    747\u001b[0m   inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcapture(inp)\n\u001b[1;32m    748\u001b[0m   captured_inputs\u001b[39m.\u001b[39mappend(inp)\n\u001b[0;32m--> 749\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(FuncGraph, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_create_op_internal(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    750\u001b[0m     op_type, captured_inputs, dtypes, input_types, name, attrs, op_def,\n\u001b[1;32m    751\u001b[0m     compute_device)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:3798\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3795\u001b[0m \u001b[39m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[1;32m   3796\u001b[0m \u001b[39m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[1;32m   3797\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mutation_lock():\n\u001b[0;32m-> 3798\u001b[0m   ret \u001b[39m=\u001b[39m Operation(\n\u001b[1;32m   3799\u001b[0m       node_def,\n\u001b[1;32m   3800\u001b[0m       \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   3801\u001b[0m       inputs\u001b[39m=\u001b[39;49minputs,\n\u001b[1;32m   3802\u001b[0m       output_types\u001b[39m=\u001b[39;49mdtypes,\n\u001b[1;32m   3803\u001b[0m       control_inputs\u001b[39m=\u001b[39;49mcontrol_inputs,\n\u001b[1;32m   3804\u001b[0m       input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[1;32m   3805\u001b[0m       original_op\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_default_original_op,\n\u001b[1;32m   3806\u001b[0m       op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[1;32m   3807\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_op_helper(ret, compute_device\u001b[39m=\u001b[39mcompute_device)\n\u001b[1;32m   3808\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:2106\u001b[0m, in \u001b[0;36mOperation.__init__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   2103\u001b[0m     control_input_ops\u001b[39m.\u001b[39mappend(control_op)\n\u001b[1;32m   2105\u001b[0m \u001b[39m# Initialize c_op from node_def and other inputs\u001b[39;00m\n\u001b[0;32m-> 2106\u001b[0m c_op \u001b[39m=\u001b[39m _create_c_op(g, node_def, inputs, control_input_ops, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[1;32m   2107\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_from_c_op(c_op\u001b[39m=\u001b[39mc_op, g\u001b[39m=\u001b[39mg)\n\u001b[1;32m   2109\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_op \u001b[39m=\u001b[39m original_op\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1972\u001b[0m, in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[1;32m   1969\u001b[0m \u001b[39m# Record the current Python stack trace as the creating stacktrace of this\u001b[39;00m\n\u001b[1;32m   1970\u001b[0m \u001b[39m# TF_Operation.\u001b[39;00m\n\u001b[1;32m   1971\u001b[0m \u001b[39mif\u001b[39;00m extract_traceback:\n\u001b[0;32m-> 1972\u001b[0m   tf_stack\u001b[39m.\u001b[39;49mextract_stack_for_op(c_op, stacklevel\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\n\u001b[1;32m   1974\u001b[0m \u001b[39mreturn\u001b[39;00m c_op\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/util/tf_stack.py:180\u001b[0m, in \u001b[0;36mextract_stack_for_op\u001b[0;34m(c_op, stacklevel)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[39m# N.B ExtractStack in tf_stack.cc will drop this frame prior to\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[39m# traversing the stack.\u001b[39;00m\n\u001b[1;32m    179\u001b[0m thread_key \u001b[39m=\u001b[39m _get_thread_key()\n\u001b[0;32m--> 180\u001b[0m _tf_stack\u001b[39m.\u001b[39;49mextract_stack_for_op(\n\u001b[1;32m    181\u001b[0m     _source_mapper_stacks[thread_key][\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49minternal_map,\n\u001b[1;32m    182\u001b[0m     _source_filter_stacks[thread_key][\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49minternal_set, c_op, stacklevel)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LTL_coef = 10\n",
    "NN_value_active = False\n",
    "search_depth = 100\n",
    "MCTS_samples = 100\n",
    "training = True\n",
    "epochs = 15\n",
    "C = 1\n",
    "tow = 0.1\n",
    "T = [25]\n",
    "K = 1\n",
    "batch_size = 32\n",
    "steps_per_epoch = 4\n",
    "idx = 0\n",
    "success_rates = []\n",
    "succes_std = []\n",
    "win_hist = []\n",
    "train_history = []\n",
    "best_val_len = {}\n",
    "for s in csrl.states(): best_val_len[s] = (0.001, 99999)\n",
    "\n",
    "num_training_epochs =  10\n",
    "# os.remove(\"Log_run.txt\")\n",
    "for i in T:\n",
    "    idx += 1\n",
    "    train_wins = 0\n",
    "    # model = build_model(ch_states[(0,0,0,0)].shape, csrl.shape[-1])\n",
    "    N, W, Q, P, visited_train = np.zeros(csrl.shape), np.zeros(csrl.shape), np.zeros(csrl.shape), np.zeros(csrl.shape), set()\n",
    "    for epoch in range(num_training_epochs):\n",
    "        t1 = time.time()\n",
    "        state_history, channeled_states, trajectory, action_history, reward_history, better_policy, best_val_len = MC_learning(csrl, model, LTL_formula,\n",
    "                predicates, csrl.reward, ch_states, N = N, W = W, Q = Q, P = P, C=C, tow=tow, n_samples=MCTS_samples, visited=visited_train,\n",
    "                start=None, search_depth=search_depth, verbose=0, T=i, K=K, NN_value_active=NN_value_active, run_num=epoch, ltl_f_rew=False, reachability=True, \n",
    "                best_val_len = best_val_len)\n",
    "        \n",
    "        if reward_history[-1]>0:\n",
    "            train_wins+=1\n",
    "            NN_value_active = True\n",
    "\n",
    "        if training and len(action_history)>0:\n",
    "            if epoch==0:\n",
    "                x_train = np.array(channeled_states)[:-1]\n",
    "                y1_train = np.array(better_policy)\n",
    "                y2_train = np.array(reward_history) + LTL_coef*reward_history[-1]\n",
    "                y2_train = y2_train[:-1]\n",
    "            else:\n",
    "                x_train = np.concatenate((x_train, np.array(channeled_states)[:-1]),0)\n",
    "                y1_train = np.concatenate((y1_train, np.array(better_policy)),0)\n",
    "                y2_train_curr = np.array(reward_history) + LTL_coef*reward_history[-1]\n",
    "                y2_train = np.concatenate((y2_train, y2_train_curr[:-1]),0)\n",
    "            tr_hist = model.fit(x_train, [y1_train, y2_train], epochs=epochs, batch_size=batch_size,\n",
    "                                steps_per_epoch=steps_per_epoch if len(x_train)>steps_per_epoch*epochs*batch_size else None, verbose=0)\n",
    "            train_history += tr_hist.history['loss']\n",
    "    print(\"Train wins:\",train_wins,\"/\", num_training_epochs)\n",
    "\n",
    "# u, d, r, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25853/263196528.py:3: RuntimeWarning: invalid value encountered in divide\n",
      "  x = (N[i]**(1/tow)) / np.sum(N[i]**(1/tow))\n"
     ]
    }
   ],
   "source": [
    "Policy = np.zeros(csrl.shape)\n",
    "for i in csrl.states():\n",
    "    x = (N[i]**(1/tow)) / np.sum(N[i]**(1/tow))\n",
    "    Policy[i] = np.nan_to_num(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_gws.append(channeled(csrl, enc, agent=False)[0,0,0,0].sum(0))\n",
    "policies.append(Policy[0,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 3, 4)]            0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 12)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                416       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 288)               4896      \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 4, 3, 3, 8)        0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,840\n",
      "Trainable params: 5,840\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3, 3, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Policy[0,:,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.prod((1,4,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? 0.6\n",
      "0 ) MCTS conf: 0.17 , det: 1.0 | ? 1\n",
      "LTL [+++]  LDBA [ 0.01 ] path: [3, 0, 0]\n",
      "? 0.05260303\n",
      "? 1\n",
      "1 ) MCTS conf: 0.96 , det: 1.0 | ? 1\n",
      "LTL [+++]  LDBA [ 0.01 ] path: [5, 2, 2]\n",
      "? 0.06288229\n",
      "? 0.9939205570480697\n",
      "? 1\n",
      "2 ) MCTS conf: 0.99 , det: 1.0 | LTL [+++]  LDBA [ 0.01 ] path: [6, 3, 0, 0]\n",
      "? 0.0014226277\n",
      "? 1\n",
      "3 ) MCTS conf: 0.99 , det: 1.0 | LTL [+++]  LDBA [ 0.01 ] path: [8, 5, 2, 2]\n",
      "? 0.34072602\n",
      "? 0.37543768\n",
      "? 0.3911557\n",
      "? 1\n",
      "4 ) MCTS conf: 0.22 , det: 1.0 | LTL [+++]  LDBA [ 0.01 ] path: [7, 6, 3, 0, 0]\n",
      "5 ) MCTS conf: 1.0 , det: 1.0 | LTL [+++]  LDBA [ 0.01 ] path: [5, 2, 2]\n",
      "6 ) MCTS conf: 1.0 , det: 1.0 | LTL [+++]  LDBA [ 0.01 ] path: [7, 6, 3, 0, 0]\n",
      "7 ) MCTS conf: 0.99 , det: 1.0 | LTL [+++]  LDBA [ 0.01 ] path: [7, 6, 3, 0, 0]\n",
      "8 ) MCTS conf: 0.19 , det: 1.0 | LTL [+++]  LDBA [ 0.01 ] path: [3, 0, 0]\n",
      "9 ) MCTS conf: 1.0 , det: 1.0 | LTL [+++]  LDBA [ 0.01 ] path: [5, 2, 2]\n",
      "Train wins: 10 / 10\n",
      "? 0.31173742\n",
      "? 0.32700434\n",
      "? 1\n",
      "None ) MCTS conf: 0.8 , det: 0.7 | LTL [+++]  LDBA [ 0.01 ] path: [1, 0, 0]\n",
      "None ) MCTS conf: 0.96 , det: 1.0 | LTL [+++]  LDBA [ 0.01 ] path: [8, 5, 2, 2]\n",
      "None ) MCTS conf: 0.18 , det: 1.0 | LTL [+++]  LDBA [ 0.01 ] path: [3, 0, 0]\n",
      "None ) MCTS conf: 1.0 , det: 1.0 | LTL [+++]  LDBA [ 0.01 ] path: [8, 5, 2, 2]\n",
      "None ) MCTS conf: 0.97 , det: 0.99 | LTL [+++]  LDBA [ 0.01 ] path: [7, 6, 3, 0, 0]\n",
      "None ) MCTS conf: 1.0 , det: 1.0 | LTL [+++]  LDBA [ 0.01 ] path: [8, 5, 2, 2]\n",
      "None ) MCTS conf: 1.0 , det: 1.0 | LTL [+++]  LDBA [ 0.01 ] path: [6, 3, 0, 0]\n",
      "None ) MCTS conf: 1.0 , det: 1.0 | LTL [+++]  LDBA [ 0.01 ] path: [5, 2, 2]\n",
      "None ) MCTS conf: 1.0 , det: 1.0 | LTL [+++]  LDBA [ 0.01 ] path: [8, 5, 2, 2]\n",
      "None ) MCTS conf: 1.0 , det: 0.99 | LTL [+++]  LDBA [ 0.01 ] path: [7, 6, 3, 0, 0]\n",
      "Test wins: 10 / 10\n"
     ]
    }
   ],
   "source": [
    "visited_states_train = []\n",
    "visited_states_test = []\n",
    "LTL_coef = 10\n",
    "NN_value_active = False\n",
    "\n",
    "search_depth = 100\n",
    "MCTS_samples = 100\n",
    "\n",
    "num_training_epochs =  10\n",
    "num_test_epochs = 10\n",
    "training = True\n",
    "epochs = 10\n",
    "C = 1\n",
    "tow = 0.1\n",
    "T = [25]\n",
    "K = 1\n",
    "batch_size = 32\n",
    "steps_per_epoch = 4\n",
    "idx = 0\n",
    "success_rates = []\n",
    "succes_std = []\n",
    "win_hist = []\n",
    "train_history = []\n",
    "\n",
    "best_val_len = {}\n",
    "for s in csrl.states(): best_val_len[s] = (0.001, 99999)\n",
    "\n",
    "# os.remove(\"Log_run.txt\")\n",
    "for i in T:\n",
    "    idx += 1\n",
    "    # TRAIN ##############################\n",
    "    train_wins = 0\n",
    "    # num_training_epochs = int(200 - 1.9*i)\n",
    "    # model = build_model(ch_states[(0,0,0,0)].shape, csrl.shape[-1])\n",
    "    N, W, Q, P, visited_train = np.zeros(csrl.shape), np.zeros(csrl.shape), np.zeros(csrl.shape), np.zeros(csrl.shape), set()\n",
    "    for epoch in range(num_training_epochs):\n",
    "        t1 = time.time()\n",
    "        state_history, channeled_states, trajectory, action_history, reward_history, better_policy, best_val_len = MC_learning(csrl, model, LTL_formula,\n",
    "                predicates, csrl.reward, ch_states, N = N, W = W, Q = Q, P = P, C=C, tow=tow, n_samples=MCTS_samples, visited=visited_train,\n",
    "                start=None, search_depth=search_depth, verbose=0, T=i, K=K, NN_value_active=NN_value_active, run_num=epoch, ltl_f_rew=False, reachability=True, \n",
    "                best_val_len = best_val_len)\n",
    "        # print(\"!\", best_val_len[(0,0,0,0)])\n",
    "        visited_states_train += state_history\n",
    "        t2 = time.time()\n",
    "        # print(t2-t1, \" run episode\")\n",
    "\n",
    "        # win = check_LTL(LTL_formula, trajectory, predicates)[0]\n",
    "        if reward_history[-1]>0:\n",
    "            train_wins+=1\n",
    "            NN_value_active = True\n",
    "\n",
    "        if training and len(action_history)>0:\n",
    "            if epoch==0:\n",
    "                x_train = np.array(channeled_states)[:-1]\n",
    "                y1_train = np.array(better_policy)\n",
    "                y2_train = np.array(reward_history) + LTL_coef*reward_history[-1]\n",
    "                # y2_train = np.array(reward_history)\n",
    "                y2_train = y2_train[:-1]\n",
    "            else:\n",
    "                x_train = np.concatenate((x_train, np.array(channeled_states)[:-1]),0)\n",
    "                y1_train = np.concatenate((y1_train, np.array(better_policy)),0)\n",
    "                y2_train_curr = np.array(reward_history) + LTL_coef*reward_history[-1]\n",
    "                # y2_train_curr = np.array(reward_history)\n",
    "                y2_train = np.concatenate((y2_train, y2_train_curr[:-1]),0)\n",
    "            t3= time.time()\n",
    "            # print(t3-t2, \" build database\")\n",
    "            tr_hist = model.fit(x_train, [y1_train, y2_train], epochs=epochs, batch_size=batch_size,\n",
    "                                steps_per_epoch=steps_per_epoch if len(x_train)>steps_per_epoch*epochs*batch_size else None, verbose=0)\n",
    "            train_history += tr_hist.history['loss']\n",
    "        # win_hist.append(win)\n",
    "        t4 = time.time()\n",
    "        # print(t4-t3, \"fit\", len(x_train))\n",
    "    print(\"Train wins:\",train_wins,\"/\", num_training_epochs)\n",
    "\n",
    "    # TEST ##############################\n",
    "    test_wins = 0\n",
    "    N, W, Q, P, visited_test = np.zeros(csrl.shape), np.zeros(csrl.shape), np.zeros(csrl.shape), np.zeros(csrl.shape), set()\n",
    "    for epoch in range(num_test_epochs):\n",
    "        \n",
    "        state_history, channeled_states, trajectory, action_history, reward_history, better_policy, best_val_len = MC_learning(csrl, model, LTL_formula,\n",
    "                predicates, csrl.reward, ch_states, N = N, W = W, Q = Q, P = P, C=1, tow=1, n_samples=MCTS_samples, visited=visited_test,\n",
    "                start=None, search_depth=search_depth, verbose=0, T=i, K=1, NN_value_active=True, reachability=True, best_val_len = best_val_len)\n",
    "\n",
    "        # win = check_LTL(LTL_formula, trajectory, predicates)[0]\n",
    "        win = reward_history[-1]\n",
    "        if win: test_wins+=1\n",
    "        win_hist.append(win)\n",
    "        visited_states_test += state_history\n",
    "        \n",
    "    success_rates.append(100*test_wins/num_test_epochs)\n",
    "    temp = np.zeros(num_test_epochs)\n",
    "    temp[:test_wins]=1\n",
    "    std = np.sqrt(num_test_epochs*np.var(temp))\n",
    "    succes_std.append((success_rates[-1]-std, success_rates[-1]+std))\n",
    "    \n",
    "    ###############################################################\n",
    "    print(\"Test wins:\",test_wins,\"/\",num_test_epochs)\n",
    "    # print(\"last reward:\", reward_history[-1], \"  | trajectory:\", trajectory)\n",
    "    # print(\"Actions:\", action_history)\n",
    "\n",
    "encode_visited_states_test = [i[1]*csrl.shape[-2]*csrl.shape[-3]+i[2]*csrl.shape[-2]+i[3] for i in visited_states_test]\n",
    "encode_visited_states_train = [i[1]*csrl.shape[-2]*csrl.shape[-3]+i[2]*csrl.shape[-2]+i[3] for i in visited_states_train]\n",
    "\n",
    "# u, d, r, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20664/263196528.py:3: RuntimeWarning: invalid value encountered in divide\n",
      "  x = (N[i]**(1/tow)) / np.sum(N[i]**(1/tow))\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_val_len ????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
